<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Camera Live Viewer & Event Recorder</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/mpegts.js/dist/mpegts.js"></script>
    <script src="https://unpkg.com/meyda@5.3.0/dist/web/meyda.min.js"></script>
    <style>
        body { font-family: 'Inter', sans-serif; }
        .video-container { min-height: 240px; }
        .event-log-item { animation: fadeIn 0.5s ease-in-out; }
        @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
        .listening-indicator span { height: 10px; width: 10px; background-color: #34D399; border-radius: 50%; display: inline-block; animation: pulse 1.5s infinite; }
        .listening-inactive span { background-color: #EF4444; animation: none; }
        @keyframes pulse {
            0% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(52, 211, 153, 0.7); }
            70% { transform: scale(1); box-shadow: 0 0 0 10px rgba(52, 211, 153, 0); }
            100% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(52, 211, 153, 0); }
        }
        .recording-indicator { background-color: #EF4444; border-radius: 50%; animation: recording-pulse 1s infinite; }
        @keyframes recording-pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }
        .audio-source-active svg { fill: #34D399; }
        #canvasContainer {
            height: 150px;
            background: linear-gradient(135deg, #1f2937 0%, #111827 100%);
            border-radius: 0.5rem;
            border: 1px solid #374151;
            position: relative;
            overflow: hidden;
        }
        #histogramCanvas { width: 100%; height: 100%; }
        #thresholdLine {
            position: absolute;
            left: 0;
            right: 0;
            height: 2px;
            background-color: #f87171;
            transition: bottom 0.2s ease;
            z-index: 10;
        }
        .fingerprint-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            opacity: 0.3;
            z-index: 5;
        }
        .video-wrapper {
            position: relative;
            width: 100%;
            height: 100%;
        }
        .message-area {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(0,0,0,0.5);
            padding: 8px 16px;
            border-radius: 8px;
            color: white;
            font-weight: bold;
            z-index: 10;
        }
    </style>
</head>
<body class="bg-gray-800 text-white flex flex-col min-h-screen p-4">

    <div class="w-full max-w-screen-xl mx-auto grid grid-cols-1 lg:grid-cols-3 gap-6">
        <div class="lg:col-span-2">
            <div class="flex justify-between items-center mb-4">
                 <h1 class="text-3xl font-bold text-center">Live Camera Feeds</h1>
                 <div class="flex items-center gap-4">
                    <label for="gridSlider" class="text-sm">Grid Layout:</label>
                    <input type="range" id="gridSlider" min="1" max="3" value="2" class="w-32">
                    <button id="reconnectAllBtn" class="bg-blue-600 hover:bg-blue-700 text-white px-3 py-1 rounded text-sm">
                        Reconnect All
                    </button>
                 </div>
            </div>
            <div id="videoGrid" class="grid grid-cols-1 md:grid-cols-2 gap-4">
                </div>
        </div>

        <div class="lg:col-span-1">
             <div class="flex items-center justify-center mb-2">
                <h2 class="text-2xl font-bold text-center">Match Status</h2>
                <div id="listeningIndicator" class="ml-4 items-center hidden listening-indicator">
                    <span><span></span></span>
                    <p class="ml-2 text-sm text-green-400">LISTENING</p>
                </div>
            </div>
            <div class="mb-4 p-4 bg-gray-900 rounded-lg shadow-lg text-center">
                <p id="gameStateDisplay" class="text-2xl font-bold text-yellow-400 tracking-wider">WAITING FOR MATCH</p>
                <p id="matchTimerDisplay" class="text-lg text-gray-300 mt-1 h-6"></p>
                <p id="nextMatchFile" class="text-sm text-blue-400 mt-2">Next Recording: <span id="nextFileName">match1_camera1.mp4</span></p>
            </div>

            <div class="bg-gray-900/50 p-4 rounded-2xl shadow-lg border border-gray-700 space-y-4">
                <h2 class="text-2xl font-bold text-center">Match Controls</h2>
                 <div class="flex items-center justify-center gap-2">
                    <div id="recordingStatus" class="hidden items-center gap-2">
                        <span class="recording-indicator w-3 h-3"></span>
                        <span class="text-red-400 font-semibold">RECORDING</span>
                    </div>
                </div>
                <div class="grid grid-cols-2 gap-3">
                    <button id="startMatchBtn" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded-md transition duration-300">Start Match</button>
                    <button id="endMatchBtn" class="bg-red-600 hover:bg-red-700 text-white font-bold py-2 px-4 rounded-md transition duration-300">End Match</button>
                </div>
                 <button id="resetMatchBtn" class="w-full bg-yellow-600 hover:bg-yellow-700 text-white font-bold py-2 px-5 rounded-md transition duration-300">Reset System</button>
            </div>

            <div class="bg-gray-900/50 p-4 rounded-2xl shadow-lg border border-gray-700 space-y-4 mt-6">
                <h2 class="text-2xl font-bold text-center">Audio Detection System</h2>
                <div class="flex items-center justify-between">
                    <label for="volumeSlider" class="text-sm font-medium text-gray-300">Master Volume:</label>
                    <span id="volumeValue" class="text-cyan-400 font-bold">50%</span>
                </div>
                <input id="volumeSlider" type="range" min="0" max="100" value="50" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
                
                <div class="flex items-center justify-between">
                    <label for="loudnessSlider" class="text-sm font-medium text-gray-300">Detection Threshold:</label>
                    <span id="loudnessValue" class="font-bold text-cyan-400">20</span>
                </div>
                <input id="loudnessSlider" type="range" min="0" max="100" value="20" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
                
                <div class="flex gap-2">
                    <button id="playTestAudioBtn" class="flex-1 bg-purple-600 hover:bg-purple-700 text-white py-2 px-3 rounded text-sm">
                        Play Live Audio
                    </button>
                    <button id="overlayFingerprintBtn" class="flex-1 bg-indigo-600 hover:bg-indigo-700 text-white py-2 px-3 rounded text-sm">
                        Show Fingerprints
                    </button>
                </div>
                
                <div id="canvasContainer">
                    <canvas id="histogramCanvas"></canvas>
                    <canvas id="fingerprintOverlay" class="fingerprint-overlay"></canvas>
                    <div id="thresholdLine"></div>
                </div>
                <button id="saveThresholdButton" class="w-full bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded-md transition duration-300">Save Detection Settings</button>
            </div>

            <h2 class="text-2xl font-bold mb-4 mt-6 text-center">Match Event Log</h2>
            <div id="eventLog" class="bg-gray-900/50 p-4 rounded-2xl shadow-lg border border-gray-700 space-y-3 h-64 overflow-y-auto"></div>
        </div>
    </div>

    <script type="text/javascript">
        const videoGrid = document.getElementById('videoGrid');
        const gameStateDisplay = document.getElementById('gameStateDisplay');
        const matchTimerDisplay = document.getElementById('matchTimerDisplay');
        const nextFileName = document.getElementById('nextFileName');
        const eventLog = document.getElementById('eventLog');
        const listeningIndicator = document.getElementById('listeningIndicator');
        const recordingStatus = document.getElementById('recordingStatus');
        const startMatchBtn = document.getElementById('startMatchBtn');
        const endMatchBtn = document.getElementById('endMatchBtn');
        const resetMatchBtn = document.getElementById('resetMatchBtn');
        const reconnectAllBtn = document.getElementById('reconnectAllBtn');
        const loudnessSlider = document.getElementById('loudnessSlider');
        const loudnessValue = document.getElementById('loudnessValue');
        const volumeSlider = document.getElementById('volumeSlider');
        const volumeValue = document.getElementById('volumeValue');
        const gridSlider = document.getElementById('gridSlider');
        const playTestAudioBtn = document.getElementById('playTestAudioBtn');
        const overlayFingerprintBtn = document.getElementById('overlayFingerprintBtn');
        const canvas = document.getElementById('histogramCanvas');
        const canvasCtx = canvas.getContext('2d');
        const fingerprintCanvas = document.getElementById('fingerprintOverlay');
        const fingerprintCtx = fingerprintCanvas.getContext('2d');
        const thresholdLine = document.getElementById('thresholdLine');
        const saveThresholdButton = document.getElementById('saveThresholdButton');

        let players = new Map();
        let audioSources = new Map();
        let referenceFingerprints = {};
        let matchTimerInterval = null;
        let audioContext, analyzer, activeAudioSourceKey = null;
        let loudnessHistory = [];
        let lastMatchTime = 0;
        let currentMatchNumber = 1;
        let isAudioListening = false;
        let isPlayingTestAudio = false;
        let showFingerprintOverlay = false;
        let matchEndedBy = 'timer'; // 'timer' or 'manual'
        
        const LOUDNESS_HISTORY_LENGTH = 50;
        const MAX_LOUDNESS = 100;
        const MATCH_DURATION = 155 * 1000;
        const MATCH_STATES = { WAITING: 'WAITING FOR MATCH', RECORDING: 'RECORDING MATCH' };
        let currentMatchState = MATCH_STATES.WAITING;

        async function initializeApp() {
            canvas.width = canvas.clientWidth;
            canvas.height = canvas.clientHeight;
            fingerprintCanvas.width = fingerprintCanvas.clientWidth;
            fingerprintCanvas.height = fingerprintCanvas.clientHeight;
            updateGameStateDisplay();
            updateNextFileName();
            
            try {
                const [cameras, fingerprints, thresholdData] = await Promise.all([
                    fetch('/api/cameras').then(res => res.json()),
                    fetch('/api/fingerprints').then(res => res.json()),
                    fetch('/api/threshold').then(res => res.json())
                ]);
                referenceFingerprints = fingerprints;
                loudnessSlider.value = thresholdData.threshold;
                loudnessValue.textContent = thresholdData.threshold;
                updateThresholdLine();
                
                console.log('Loaded cameras:', cameras);
                for (const key in cameras) {
                    addCameraStream(key, cameras[key]);
                }
                
                // Immediate audio setup after camera initialization
                setTimeout(() => {
                    if (activeAudioSourceKey) {
                        startAnalysis(true);
                    }
                }, 1000);
                
            } catch (error) {
                console.error("Initialization failed:", error);
                logEvent('System Error', 'Failed to initialize: ' + error.message);
            }
        }

        function addCameraStream(cameraKey, cameraConfig) {
            if (players.has(cameraKey)) return;

            console.log(`Adding camera stream: ${cameraKey}`, cameraConfig);

            const container = document.createElement('div');
            container.id = `container-${cameraKey}`;
            container.className = 'video-container bg-black rounded-lg shadow-inner overflow-hidden relative flex flex-col';
            
            const header = document.createElement('div');
            header.className = 'p-2 bg-gray-700/50 flex items-center justify-between';
            header.innerHTML = `
                <span class="font-bold">${cameraConfig.name}</span>
                <div class="flex items-center gap-2">
                    <button class="mic-button p-1" data-key="${cameraKey}" title="Use as audio source">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 text-white" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd" /></svg>
                    </button>
                    <button class="reconnect-button bg-blue-600 hover:bg-blue-700 px-2 py-1 rounded text-xs" data-key="${cameraKey}" title="Reconnect camera">↻</button>
                    <button class="remove-button text-red-500 font-bold px-2" data-key="${cameraKey}" title="Remove camera">×</button>
                </div>
            `;
            
            const videoWrapper = document.createElement('div');
            videoWrapper.className = 'video-wrapper flex-grow';

            const videoElement = document.createElement('video');
            videoElement.id = `video-${cameraKey}`;
            videoElement.className = 'w-full h-full object-cover';
            videoElement.autoplay = true;
            videoElement.muted = true;
            videoElement.playsinline = true;

            const messageArea = document.createElement('div');
            messageArea.id = `message-${cameraKey}`;
            messageArea.className = 'message-area hidden';

            videoWrapper.appendChild(videoElement);
            videoWrapper.appendChild(messageArea);
            container.appendChild(header);
            container.appendChild(videoWrapper);
            videoGrid.appendChild(container);

            // Event listeners
            header.querySelector('.remove-button').onclick = () => removeCamera(cameraKey);
            header.querySelector('.reconnect-button').onclick = () => reconnectCamera(cameraKey);
            header.querySelector('.mic-button').onclick = () => setAudioSource(cameraKey);

            const playerState = {
                player: null,
                videoElement,
                container,
                messageArea,
                reconnectAttempts: 0,
                maxReconnectAttempts: 5
            };
            players.set(cameraKey, playerState);
            
            attemptStreamConnection(cameraKey);

            if (!activeAudioSourceKey) {
                setAudioSource(cameraKey);
            }
        }

        function reconnectCamera(cameraKey) {
            const state = players.get(cameraKey);
            if (!state) return;
            
            state.reconnectAttempts = 0;
            attemptStreamConnection(cameraKey);
            logEvent(`Manual reconnect: ${cameraKey}`, 'System');
        }

        function reconnectAllCameras() {
            players.forEach((state, cameraKey) => {
                state.reconnectAttempts = 0;
                attemptStreamConnection(cameraKey);
            });
            logEvent('Reconnecting all cameras', 'System');
        }

        function attemptStreamConnection(cameraKey) {
            const state = players.get(cameraKey);
            if (!state) return;

            console.log(`Attempting to connect to camera: ${cameraKey}`);
            state.messageArea.textContent = 'Connecting...';
            state.messageArea.classList.remove('hidden');

            if (state.player) {
                try {
                    state.player.destroy();
                } catch (e) {
                    console.warn(`Error destroying player for ${cameraKey}:`, e);
                }
            }

            const streamUrl = `/stream?camera=${cameraKey}`;
            console.log(`Stream URL for ${cameraKey}: ${streamUrl}`);

            state.player = mpegts.createPlayer({
                type: 'flv', 
                isLive: true, 
                url: streamUrl,
                cors: true, 
                hasAudio: true, 
                hasVideo: true
            });
            
            state.player.on(mpegts.Events.MEDIA_INFO, (mediaInfo) => {
                console.log(`[CLIENT] Connected to ${cameraKey}`, mediaInfo);
                state.messageArea.classList.add('hidden');
                state.reconnectAttempts = 0;
                logEvent(`Camera Connected: ${cameraKey}`, 'System');
            });

            state.player.on(mpegts.Events.ERROR, (type, details, fatal) => {
                console.error(`[CLIENT] Stream error for ${cameraKey}:`, type, details, fatal);
                state.reconnectAttempts++;
                if (state.reconnectAttempts <= state.maxReconnectAttempts) {
                    const delay = 1000 * state.reconnectAttempts;
                    state.messageArea.textContent = `Connection failed. Retrying in ${delay/1000}s...`;
                    setTimeout(() => attemptStreamConnection(cameraKey), delay);
                } else {
                     state.messageArea.textContent = 'Connection Failed - Check camera settings';
                     logEvent(`Camera Failed: ${cameraKey}`, 'Check IP/port settings');
                }
            });

            try {
                state.player.attachMediaElement(state.videoElement);
                state.player.load();
                state.player.play().catch(e => {
                    console.error(`Play error for ${cameraKey}:`, e);
                    state.messageArea.textContent = 'Play Error - Check stream format';
                });
            } catch (error) {
                console.error(`Failed to setup player for ${cameraKey}:`, error);
                state.messageArea.textContent = 'Setup Error';
            }
        }
        
        function removeCamera(cameraKey) {
            if (!players.has(cameraKey)) return;
            const { player, container } = players.get(cameraKey);
            
            try {
                if (player) player.destroy();
            } catch (e) {
                console.warn(`Error destroying player for ${cameraKey}:`, e);
            }
            
            container.remove();
            players.delete(cameraKey);
            
            if (audioSources.has(cameraKey)) {
                audioSources.get(cameraKey).sourceNode.disconnect();
                audioSources.delete(cameraKey);
            }
            
            if (activeAudioSourceKey === cameraKey) {
                activeAudioSourceKey = null;
                if (analyzer) analyzer.stop();
                analyzer = null;
                isAudioListening = false;
                updateListeningIndicator();
                if (players.size > 0) {
                    setAudioSource(players.keys().next().value);
                }
            }
        }

        function setAudioSource(cameraKey) {
            if (!players.has(cameraKey) || activeAudioSourceKey === cameraKey) return;
            
            players.forEach((p, key) => {
                p.videoElement.muted = key !== cameraKey;
            });

            activeAudioSourceKey = cameraKey;
            console.log(`[AUDIO] Switched audio source to ${cameraKey}`);
            
            document.querySelectorAll('.mic-button').forEach(btn => btn.classList.remove('audio-source-active'));
            document.querySelector(`.mic-button[data-key="${cameraKey}"]`).classList.add('audio-source-active');

            // Force immediate audio context resume and analysis start
            startAnalysis(true); // Pass force flag
        }

        function updateListeningIndicator() {
            // Show listening status based on actual analyzer state, not just flags
            const isActuallyListening = analyzer && analyzer.running && currentMatchState === MATCH_STATES.WAITING;
            
            if (isActuallyListening) {
                listeningIndicator.classList.remove('hidden', 'listening-inactive');
                listeningIndicator.classList.add('listening-indicator');
                listeningIndicator.querySelector('p').textContent = 'LISTENING';
                listeningIndicator.querySelector('p').className = 'ml-2 text-sm text-green-400';
            } else {
                listeningIndicator.classList.remove('listening-indicator');
                listeningIndicator.classList.add('listening-inactive');
                listeningIndicator.querySelector('p').textContent = currentMatchState === MATCH_STATES.RECORDING ? 'RECORDING' : 'NOT LISTENING';
                listeningIndicator.querySelector('p').className = 'ml-2 text-sm text-red-400';
            }
            listeningIndicator.classList.remove('hidden');
        }

        async function startAnalysis(forceRestart = false) {
            // Stop existing analyzer if force restart or if it exists
            if (analyzer && (forceRestart || analyzer.running)) {
                try {
                    analyzer.stop();
                } catch (e) {
                    console.warn('[AUDIO] Error stopping existing analyzer:', e);
                }
                analyzer = null;
            }
            
            if (!activeAudioSourceKey || !players.has(activeAudioSourceKey)) {
                console.warn('[AUDIO] No active audio source available');
                isAudioListening = false;
                updateListeningIndicator();
                return;
            }

            try {
                // Create or resume audio context
                if (!audioContext || audioContext.state === 'closed') {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                
                // Force resume if suspended - this is key for immediate activation
                if (audioContext.state === 'suspended') {
                    console.log('[AUDIO] Resuming suspended audio context...');
                    await audioContext.resume();
                }
                
                const { videoElement } = players.get(activeAudioSourceKey);
                let sourceNode;
                
                // Reuse or create source node
                if (audioSources.has(activeAudioSourceKey)) {
                    sourceNode = audioSources.get(activeAudioSourceKey).sourceNode;
                } else {
                    sourceNode = audioContext.createMediaElementSource(videoElement);
                    sourceNode.connect(audioContext.destination);
                    audioSources.set(activeAudioSourceKey, { sourceNode });
                }
                
                // Create new analyzer
                analyzer = Meyda.createMeydaAnalyzer({
                    audioContext,
                    source: sourceNode,
                    bufferSize: 512,
                    featureExtractors: ["mfcc", "loudness"],
                    callback: features => {
                        // Update histogram with loudness for UI
                        if (features?.loudness?.total) {
                            loudnessHistory.push(features.loudness.total);
                            if (loudnessHistory.length > LOUDNESS_HISTORY_LENGTH) loudnessHistory.shift();
                            drawHistogram();
                        }

                        // Match detection - removed the debounce delay issue
                        if (currentMatchState === MATCH_STATES.WAITING && features?.mfcc) {
                            compareAndFindMatch(features.mfcc);
                        }
                    }
                });
                
                analyzer.start();
                isAudioListening = true;
                console.log(`[AUDIO] Analysis started successfully for ${activeAudioSourceKey}`);
                
                // Immediate UI update
                updateListeningIndicator();
                
            } catch (error) {
                console.error(`[AUDIO] Error starting audio analysis:`, error);
                isAudioListening = false;
                analyzer = null;
                updateListeningIndicator();
            }
        }

        function compareAndFindMatch(liveMfcc) {
            // Reduced debounce from 5 seconds to 2 seconds for faster response
            if (Date.now() - lastMatchTime < 2000) return; 

            let bestMatch = { name: null, distance: Infinity };
            const MATCH_THRESHOLD = 20;

            for (const name in referenceFingerprints) {
                if (name.toLowerCase().includes('start')) {
                    const fingerprintData = referenceFingerprints[name];
                    const refMfcc = fingerprintData.mfcc || fingerprintData;
                    let distance = Math.sqrt(refMfcc.reduce((sum, val, i) => sum + Math.pow(val - liveMfcc[i], 2), 0));
                    if (distance < bestMatch.distance) {
                        bestMatch = { distance, name };
                    }
                }
            }

            if (bestMatch.distance < MATCH_THRESHOLD) {
                lastMatchTime = Date.now();
                logEvent(`Audio Detection: ${bestMatch.name}`, bestMatch.distance.toFixed(2));
                sendMatchEvent('MATCH_START');
            }
        }

        function sendMatchEvent(eventType) {
            if (eventType === 'MATCH_START' && currentMatchState !== MATCH_STATES.WAITING) return;
            
            const isManual = eventType === 'MATCH_ABORT' || 
                            (eventType === 'MATCH_START' && !isAudioListening);
            
            if (eventType === 'MATCH_ABORT') {
                matchEndedBy = 'manual';
            } else if (eventType === 'MATCH_START') {
                matchEndedBy = 'timer';
            }
            
            fetch('/api/match-event', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ eventType, matchNumber: currentMatchNumber, isManual })
            }).then(res => res.json()).then(data => {
                if (data.success) {
                    if (eventType === 'MATCH_START') {
                        currentMatchState = MATCH_STATES.RECORDING;
                        startMatchTimer();
                        // Don't stop listening - just update UI
                        logEvent(`Match ${currentMatchNumber} Started`, isManual ? 'Manual' : 'Audio');
                    } else {
                        currentMatchState = MATCH_STATES.WAITING;
                        stopMatchTimer();
                        logEvent(`Match ${currentMatchNumber} Ended`, `${matchEndedBy === 'manual' ? 'Manual intervention' : 'Timer expired'}`);
                        currentMatchNumber++;
                        updateNextFileName();
                        
                        // Immediately restart analysis after match ends
                        setTimeout(() => {
                            startAnalysis(true);
                        }, 100); // Very short delay to ensure state is updated
                    }
                    updateGameStateDisplay();
                    updateListeningIndicator();
                }
            }).catch(err => console.error('Error sending match event:', err));
        }

        // Enhanced volume slider event listener with immediate audio context activation
        volumeSlider.addEventListener('input', async (e) => {
            const volume = e.target.value / 100;
            volumeValue.textContent = e.target.value + '%';
            
            players.forEach(p => {
                p.videoElement.volume = volume;
            });
            
            // Ensure audio context is active when user interacts
            if (audioContext) {
                if (audioContext.state === 'suspended') {
                    try {
                        await audioContext.resume();
                        console.log('[AUDIO] Audio context resumed via volume control');
                        // Restart analysis if we have an active source
                        if (activeAudioSourceKey && currentMatchState === MATCH_STATES.WAITING) {
                            startAnalysis(true);
                        }
                    } catch (e) {
                        console.warn('[AUDIO] Failed to resume audio context:', e);
                    }
                }
                
                if (activeAudioSourceKey && players.has(activeAudioSourceKey)) {
                    players.get(activeAudioSourceKey).videoElement.muted = false;
                }
            }
        });

        function activateAudioOnInteraction() {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    console.log('[AUDIO] Audio context resumed via user interaction');
                    if (activeAudioSourceKey && currentMatchState === MATCH_STATES.WAITING) {
                        startAnalysis(true);
                    }
                });
            }
        }

        document.addEventListener('click', activateAudioOnInteraction, { once: false });
        document.addEventListener('keydown', activateAudioOnInteraction, { once: false });
        
        function updateNextFileName() {
            const firstCameraKey = players.size > 0 ? players.keys().next().value : 'camera1';
            nextFileName.textContent = `match${currentMatchNumber}_${firstCameraKey}.mp4`;
        }

        startMatchBtn.addEventListener('click', () => sendMatchEvent('MATCH_START'));
        endMatchBtn.addEventListener('click', () => {
            matchEndedBy = 'manual';
            sendMatchEvent('MATCH_ABORT');
        });
        resetMatchBtn.addEventListener('click', () => {
            matchEndedBy = 'manual';
            sendMatchEvent('MATCH_ABORT');
        });
        reconnectAllBtn.addEventListener('click', reconnectAllCameras);

        function startMatchTimer() {
            const endTime = Date.now() + MATCH_DURATION;
            matchTimerInterval = setInterval(() => {
                const remaining = endTime - Date.now();
                if (remaining <= 0) {
                    stopMatchTimer();
                    matchTimerDisplay.textContent = '00:00';
                    currentMatchState = MATCH_STATES.WAITING;
                    matchEndedBy = 'timer';
                    sendMatchEvent('MATCH_ABORT'); // This will log as timer expired
                    updateGameStateDisplay();
                } else {
                    const minutes = Math.floor(remaining / 60000);
                    const seconds = Math.floor((remaining % 60000) / 1000);
                    matchTimerDisplay.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
                }
            }, 1000);
        }

        function stopMatchTimer() {
            if (matchTimerInterval) clearInterval(matchTimerInterval);
            matchTimerInterval = null;
            matchTimerDisplay.textContent = '';
        }
        
        function updateGameStateDisplay() {
            gameStateDisplay.textContent = currentMatchState;
            const isRec = currentMatchState === MATCH_STATES.RECORDING;
            recordingStatus.classList.toggle('hidden', !isRec);
            recordingStatus.classList.toggle('flex', isRec);
            startMatchBtn.disabled = isRec;
            endMatchBtn.disabled = !isRec;
        }

        function logEvent(name, details) {
            const now = new Date();
            const timestamp = `${now.getHours().toString().padStart(2, '0')}:${now.getMinutes().toString().padStart(2, '0')}:${now.getSeconds().toString().padStart(2, '0')}`;
            const eventItem = document.createElement('div');
            eventItem.className = 'bg-gray-800 p-3 rounded-lg event-log-item';
            eventItem.innerHTML = `
                <div class="flex justify-between items-center">
                    <span class="font-bold text-lg text-cyan-400">${name}</span>
                    <span class="text-xs text-gray-400">${timestamp}</span>
                </div>
                <div class="text-sm text-gray-300 mt-1">${details}</div>
            `;
            eventLog.prepend(eventItem);
        }

        function drawHistogram() {
            const w = canvas.width;
            const h = canvas.height;
            canvasCtx.clearRect(0, 0, w, h);
            
            // Draw live audio waveform
            canvasCtx.beginPath();
            canvasCtx.strokeStyle = '#38bdf8';
            canvasCtx.lineWidth = 2.5;
            canvasCtx.lineJoin = 'round';
            const step = w / (LOUDNESS_HISTORY_LENGTH - 1);
            let firstLoudness = loudnessHistory[0] || 0;
            let firstY = h - Math.min(h, (firstLoudness / MAX_LOUDNESS) * h);
            canvasCtx.moveTo(0, firstY);
            for (let i = 1; i < loudnessHistory.length; i++) {
                const loudness = loudnessHistory[i] || 0;
                const x = i * step;
                const y = h - Math.min(h, (loudness / MAX_LOUDNESS) * h);
                canvasCtx.lineTo(x, y);
            }
            canvasCtx.stroke();

            // Draw fingerprint overlay if enabled
            if (showFingerprintOverlay) {
                drawFingerprintOverlay();
            }
        }

        function drawFingerprintOverlay() {
            const w = fingerprintCanvas.width;
            const h = fingerprintCanvas.height;
            fingerprintCtx.clearRect(0, 0, w, h);
            
            let yOffset = 0;
            const colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#feca57'];
            let colorIndex = 0;
            
            for (const [name, fingerprintData] of Object.entries(referenceFingerprints)) {
                const mfccData = fingerprintData.mfcc || fingerprintData; // Handle both formats
                
                fingerprintCtx.beginPath();
                fingerprintCtx.strokeStyle = colors[colorIndex % colors.length];
                fingerprintCtx.lineWidth = 1.5;
                fingerprintCtx.globalAlpha = 0.6;
                
                const step = w / (mfccData.length - 1);
                const normalizedData = mfccData.map(val => Math.abs(val) * 10);
                const maxVal = Math.max(...normalizedData);
                
                fingerprintCtx.moveTo(0, h - yOffset - 20);
                for (let i = 0; i < mfccData.length && i < 50; i++) {
                    const x = i * step;
                    const y = h - yOffset - 20 - (normalizedData[i] / maxVal) * 30;
                    fingerprintCtx.lineTo(x, y);
                }
                fingerprintCtx.stroke();
                
                // Label
                fingerprintCtx.fillStyle = colors[colorIndex % colors.length];
                fingerprintCtx.font = '10px Inter';
                fingerprintCtx.fillText(name.substring(0, 12), 5, h - yOffset - 5);
                
                yOffset += 35;
                colorIndex++;
            }
            fingerprintCtx.globalAlpha = 1.0;
        }

        function updateThresholdLine() {
            const threshold = parseFloat(loudnessSlider.value);
            const percent = (threshold / MAX_LOUDNESS) * 100;
            thresholdLine.style.bottom = `${percent}%`;
        }

        // Event Listeners
        volumeSlider.addEventListener('input', (e) => {
            const volume = e.target.value / 100;
            volumeValue.textContent = e.target.value + '%';
            players.forEach(p => {
                p.videoElement.volume = volume;
            });
             if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    if (activeAudioSourceKey && players.has(activeAudioSourceKey)) {
                        players.get(activeAudioSourceKey).videoElement.muted = false;
                    }
                });
            } else if (activeAudioSourceKey && players.has(activeAudioSourceKey)) {
                 players.get(activeAudioSourceKey).videoElement.muted = false;
            }
        });

        gridSlider.addEventListener('input', (e) => {
            const cols = e.target.value;
            videoGrid.className = `grid grid-cols-1 md:grid-cols-${cols} gap-4`;
        });

        loudnessSlider.addEventListener('input', () => {
            loudnessValue.textContent = loudnessSlider.value;
            updateThresholdLine();
        });

        playTestAudioBtn.addEventListener('click', () => {
            if (!isPlayingTestAudio) {
                isPlayingTestAudio = true;
                playTestAudioBtn.textContent = 'Stop Audio';
                playTestAudioBtn.classList.replace('bg-purple-600', 'bg-red-600');
                playTestAudioBtn.classList.replace('hover:bg-purple-700', 'hover:bg-red-700');
                
                if (activeAudioSourceKey && players.has(activeAudioSourceKey)) {
                    const videoElement = players.get(activeAudioSourceKey).videoElement;
                    videoElement.muted = false;
                    videoElement.volume = volumeSlider.value / 100;
                }
            } else {
                isPlayingTestAudio = false;
                playTestAudioBtn.textContent = 'Play Live Audio';
                playTestAudioBtn.classList.replace('bg-red-600', 'bg-purple-600');
                playTestAudioBtn.classList.replace('hover:bg-red-700', 'hover:bg-purple-700');
                
                if (activeAudioSourceKey && players.has(activeAudioSourceKey)) {
                    const videoElement = players.get(activeAudioSourceKey).videoElement;
                    videoElement.muted = true;
                }
            }
        });

        overlayFingerprintBtn.addEventListener('click', () => {
            showFingerprintOverlay = !showFingerprintOverlay;
            if (showFingerprintOverlay) {
                overlayFingerprintBtn.textContent = 'Hide Fingerprints';
                overlayFingerprintBtn.classList.replace('bg-indigo-600', 'bg-orange-600');
                overlayFingerprintBtn.classList.replace('hover:bg-indigo-700', 'hover:bg-orange-700');
                fingerprintCanvas.style.display = 'block';
            } else {
                overlayFingerprintBtn.textContent = 'Show Fingerprints';
                overlayFingerprintBtn.classList.replace('bg-orange-600', 'bg-indigo-600');
                overlayFingerprintBtn.classList.replace('hover:bg-orange-700', 'hover:bg-indigo-700');
                fingerprintCanvas.style.display = 'none';
                fingerprintCtx.clearRect(0, 0, fingerprintCanvas.width, fingerprintCanvas.height);
            }
        });

        saveThresholdButton.addEventListener('click', async () => {
            const threshold = loudnessSlider.value;
            saveThresholdButton.textContent = 'Saving...';
            try {
                await fetch('/api/threshold', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ threshold: parseFloat(threshold) })
                });
                saveThresholdButton.textContent = 'Saved!';
                logEvent('Detection settings saved', `Threshold: ${threshold}`);
            } catch (error) {
                console.error('Failed to save threshold:', error);
                saveThresholdButton.textContent = 'Error!';
            } finally {
                setTimeout(() => { saveThresholdButton.textContent = 'Save Detection Settings'; }, 2000);
            }
        });

        initializeApp();
    </script>
</body>
</html>